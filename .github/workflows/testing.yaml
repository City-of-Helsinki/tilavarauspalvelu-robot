name: Varaamo Robot Framework Tests

on:
  workflow_dispatch:
    inputs:
      test_suite:
        description: "Select which test suite to run"
        required: true
        default: "All"
        type: choice
        options:
          - Smoke
          - All
          - Tests_user_desktop_FI
          - Tests_user_mobile_iphone_FI
          - Tests_user_mobile_android_FI
          - Tests_users_with_admin_desktop
          - Tests_admin_desktop_FI
          - Tests_admin_notifications_serial
      execution_mode:
        description: "Select execution mode"
        required: true
        default: "parallel"
        type: choice
        options:
          - parallel
          - sequential
      enable_har_recording:
        description: "Enable HAR recording for network traffic analysis"
        required: false
        default: false
        type: boolean

jobs:
  test:
    name: 🤖 Robot Framework Tests
    runs-on: ubuntu-latest
    timeout-minutes: 60 # Prevent hanging tests
    env:
      TZ: Europe/Helsinki # Ensure consistent timezone for tests
      ACCESS_TOKEN: ${{ secrets.ACCESS_TOKEN }}
      REFRESH_TOKEN: ${{ secrets.REFRESH_TOKEN }}
      CLIENT_ID: ${{ secrets.CLIENT_ID }}
      CLIENT_SECRET: ${{ secrets.CLIENT_SECRET }}
      WAF_BYPASS_SECRET: ${{ secrets.WAF_BYPASS_SECRET }}
      # Process counts for parallel execution
      DESKTOP_PROCESSES: 3
      ADMIN_PROCESSES: 3
      MOBILE_PROCESSES: 3
      ALL_SUITES_PROCESSES: 3

    steps:
      - uses: actions/checkout@v4

      # Set up Docker with caching support
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      # Build Docker image with GitHub Actions cache for faster builds
      - name: Build and cache Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          load: true
          tags: robotframework-tests:latest
          cache-from: type=gha
          cache-to: type=gha,mode=max

      # Configure test arguments based on selected suite and execution mode
      - name: Determine test configuration
        id: config
        run: |
          EXECUTION_MODE="${{ github.event.inputs.execution_mode }}"
          ENABLE_HAR="${{ github.event.inputs.enable_har_recording }}"

          # Convert boolean to Robot Framework format
          if [ "$ENABLE_HAR" = "true" ]; then
            HAR_VARIABLE="--variable ENABLE_HAR_RECORDING:True"
          else
            HAR_VARIABLE="--variable ENABLE_HAR_RECORDING:False"
          fi

          # Set execution tool and base flags
          if [ "$EXECUTION_MODE" = "parallel" ]; then
            echo "execution_tool=pabot" >> $GITHUB_OUTPUT
            echo "base_flags=--testlevelsplit --pabotlib --exclude serialonly --resourcefile /opt/robotframework/tests/Resources/test_value_sets.dat $HAR_VARIABLE" >> $GITHUB_OUTPUT
          else
            echo "execution_tool=robot" >> $GITHUB_OUTPUT
            echo "base_flags=--variable FORCE_SINGLE_USER:True $HAR_VARIABLE" >> $GITHUB_OUTPUT
          fi

          case "${{ github.event.inputs.test_suite }}" in
            Smoke)
              # Run only smoke tests from specific files
              if [ "$EXECUTION_MODE" = "parallel" ]; then
                echo "suite_args=--processes 2 --outputdir /opt/robotframework/reports --include smoke --name \"Smoke Tests\" /opt/robotframework/tests/Tests_user_desktop_FI.robot /opt/robotframework/tests/Tests_admin_desktop_FI.robot" >> $GITHUB_OUTPUT
              else
                echo "suite_args=--outputdir /opt/robotframework/reports --include smoke --name \"Smoke Tests\" /opt/robotframework/tests/Tests_user_desktop_FI.robot /opt/robotframework/tests/Tests_admin_desktop_FI.robot" >> $GITHUB_OUTPUT
              fi
              echo "run_type=smoke_only" >> $GITHUB_OUTPUT
              ;;
            All)
              # For "All": first run smoke tests, then full suite if smoke passes
              if [ "$EXECUTION_MODE" = "parallel" ]; then
                echo "smoke_args=--processes 2 --outputdir /opt/robotframework/reports/smoke --include smoke --name \"Smoke Tests\" /opt/robotframework/tests/Tests_user_desktop_FI.robot /opt/robotframework/tests/Tests_admin_desktop_FI.robot" >> $GITHUB_OUTPUT
                echo "full_args=--processes $ALL_SUITES_PROCESSES --outputdir /opt/robotframework/reports/full --nostatusrc --name \"All Test Suites\" /opt/robotframework/tests/Tests_user_desktop_FI.robot /opt/robotframework/tests/Tests_admin_desktop_FI.robot /opt/robotframework/tests/Tests_admin_notifications_serial.robot /opt/robotframework/tests/Tests_users_with_admin_desktop.robot /opt/robotframework/tests/Tests_user_mobile_android_FI.robot /opt/robotframework/tests/Tests_user_mobile_iphone_FI.robot" >> $GITHUB_OUTPUT
              else
                echo "smoke_args=--outputdir /opt/robotframework/reports/smoke --include smoke --name \"Smoke Tests\" /opt/robotframework/tests/Tests_user_desktop_FI.robot /opt/robotframework/tests/Tests_admin_desktop_FI.robot" >> $GITHUB_OUTPUT
                echo "full_args=--outputdir /opt/robotframework/reports/full --nostatusrc --name \"All Test Suites\" /opt/robotframework/tests/Tests_user_desktop_FI.robot /opt/robotframework/tests/Tests_admin_desktop_FI.robot /opt/robotframework/tests/Tests_admin_notifications_serial.robot /opt/robotframework/tests/Tests_users_with_admin_desktop.robot /opt/robotframework/tests/Tests_user_mobile_android_FI.robot /opt/robotframework/tests/Tests_user_mobile_iphone_FI.robot" >> $GITHUB_OUTPUT
              fi
              echo "run_type=smoke_first" >> $GITHUB_OUTPUT
              ;;
            Tests_user_desktop_FI)
              # Run specific desktop user tests
              if [ "$EXECUTION_MODE" = "parallel" ]; then
                echo "suite_args=--processes $DESKTOP_PROCESSES --outputdir /opt/robotframework/reports --nostatusrc /opt/robotframework/tests/Tests_user_desktop_FI.robot" >> $GITHUB_OUTPUT
              else
                echo "suite_args=--outputdir /opt/robotframework/reports --nostatusrc /opt/robotframework/tests/Tests_user_desktop_FI.robot" >> $GITHUB_OUTPUT
              fi
              echo "run_type=single_suite" >> $GITHUB_OUTPUT
              ;;
            Tests_user_mobile_iphone_FI)
              # Run iPhone mobile tests
              if [ "$EXECUTION_MODE" = "parallel" ]; then
                echo "suite_args=--processes $MOBILE_PROCESSES --outputdir /opt/robotframework/reports --nostatusrc /opt/robotframework/tests/Tests_user_mobile_iphone_FI.robot" >> $GITHUB_OUTPUT
              else
                echo "suite_args=--outputdir /opt/robotframework/reports --nostatusrc /opt/robotframework/tests/Tests_user_mobile_iphone_FI.robot" >> $GITHUB_OUTPUT
              fi
              echo "run_type=single_suite" >> $GITHUB_OUTPUT
              ;;
            Tests_user_mobile_android_FI)
              # Run Android mobile tests
              if [ "$EXECUTION_MODE" = "parallel" ]; then
                echo "suite_args=--processes $MOBILE_PROCESSES --outputdir /opt/robotframework/reports --nostatusrc /opt/robotframework/tests/Tests_user_mobile_android_FI.robot" >> $GITHUB_OUTPUT
              else
                echo "suite_args=--outputdir /opt/robotframework/reports --nostatusrc /opt/robotframework/tests/Tests_user_mobile_android_FI.robot" >> $GITHUB_OUTPUT
              fi
              echo "run_type=single_suite" >> $GITHUB_OUTPUT
              ;;
            Tests_users_with_admin_desktop)
              # Run admin user tests
              if [ "$EXECUTION_MODE" = "parallel" ]; then
                echo "suite_args=--processes $ADMIN_PROCESSES --outputdir /opt/robotframework/reports --nostatusrc /opt/robotframework/tests/Tests_users_with_admin_desktop.robot" >> $GITHUB_OUTPUT
              else
                echo "suite_args=--outputdir /opt/robotframework/reports --nostatusrc /opt/robotframework/tests/Tests_users_with_admin_desktop.robot" >> $GITHUB_OUTPUT
              fi
              echo "run_type=single_suite" >> $GITHUB_OUTPUT
              ;;
            Tests_admin_desktop_FI)
              # Run admin desktop tests
              if [ "$EXECUTION_MODE" = "parallel" ]; then
                echo "suite_args=--processes $ADMIN_PROCESSES --outputdir /opt/robotframework/reports --nostatusrc /opt/robotframework/tests/Tests_admin_desktop_FI.robot" >> $GITHUB_OUTPUT
              else
                echo "suite_args=--outputdir /opt/robotframework/reports --nostatusrc /opt/robotframework/tests/Tests_admin_desktop_FI.robot" >> $GITHUB_OUTPUT
              fi
              echo "run_type=single_suite" >> $GITHUB_OUTPUT
              ;;
            Tests_admin_notifications_serial)
              # Admin notifications always run sequentially (marked as serialonly)
              echo "execution_tool=robot" >> $GITHUB_OUTPUT
              echo "base_flags=--variable FORCE_SINGLE_USER:True $HAR_VARIABLE" >> $GITHUB_OUTPUT
              echo "suite_args=--outputdir /opt/robotframework/reports --nostatusrc /opt/robotframework/tests/Tests_admin_notifications_serial.robot" >> $GITHUB_OUTPUT
              echo "run_type=single_suite" >> $GITHUB_OUTPUT
              ;;
          esac

      # Create reports directory with proper permissions
      - name: Prepare reports folder
        run: |
          mkdir -p "${{ github.workspace }}/Reports"
          chmod 777 "${{ github.workspace }}/Reports"
          # Create output directory for HAR files
          mkdir -p "${{ github.workspace }}/output"
          chmod 777 "${{ github.workspace }}/output"
          # Create downloads directory for email tests
          mkdir -p "${{ github.workspace }}/TestSuites/Resources/downloads"
          chmod 777 "${{ github.workspace }}/TestSuites/Resources/downloads"

      # Run smoke tests first (only for "All" option)
      - name: Run Smoke Tests
        id: smoke_tests
        if: steps.config.outputs.run_type == 'smoke_first'
        run: |
          echo "🚀 Starting smoke tests with ${{ steps.config.outputs.execution_tool }}..."
          set +e  # Don't exit on error
          docker run --rm \
            -e ACCESS_TOKEN -e REFRESH_TOKEN -e CLIENT_ID -e CLIENT_SECRET -e WAF_BYPASS_SECRET -e TZ=Europe/Helsinki \
            -v "${{ github.workspace }}/TestSuites:/opt/robotframework/tests" \
            -v "${{ github.workspace }}/Reports:/opt/robotframework/reports" \
            -v "${{ github.workspace }}/output:/opt/robotframework/output" \
            robotframework-tests:latest ${{ steps.config.outputs.execution_tool }} \
            ${{ steps.config.outputs.base_flags }} \
            ${{ steps.config.outputs.smoke_args }}

          ROBOT_EXIT_CODE=$?
          # Smoke tests should block full suite if ANY test fails (exit code > 0)
          # Exit code 0 = all tests passed (continue to full suite)
          # Exit code > 0 = some tests failed or execution error (block full suite)
          if [ $ROBOT_EXIT_CODE -gt 0 ]; then
            echo "SMOKE_EXECUTION_FAILED=true" >> $GITHUB_ENV
            # Don't create annotations here - let the evaluation step handle messaging
          else
            echo "SMOKE_EXECUTION_FAILED=false" >> $GITHUB_ENV
            echo "✅ All smoke tests passed, proceeding to full test suite..."
          fi

      # Check smoke test results and provide clear messaging
      - name: Evaluate Smoke Test Results
        if: steps.config.outputs.run_type == 'smoke_first'
        run: |
          if [ "$SMOKE_EXECUTION_FAILED" = "true" ]; then
            echo "::error title=Smoke Tests Failed::❌ Smoke tests failed! Full test suite blocked"
          else
            echo "::notice title=Smoke Tests Passed::✅ All smoke tests passed! Proceeding to full test suite..."
          fi

      # Run full test suite only if smoke tests executed successfully
      - name: Run Full Test Suite
        if: steps.config.outputs.run_type == 'smoke_first' && env.SMOKE_EXECUTION_FAILED != 'true'
        run: |
          echo "🚀 Smoke tests succeeded; running full test suite with ${{ steps.config.outputs.execution_tool }}..."
          set +e  # Don't exit on error to ensure we can collect results
          docker run --rm \
            -e ACCESS_TOKEN -e REFRESH_TOKEN -e CLIENT_ID -e CLIENT_SECRET -e WAF_BYPASS_SECRET -e TZ=Europe/Helsinki \
            -v "${{ github.workspace }}/TestSuites:/opt/robotframework/tests" \
            -v "${{ github.workspace }}/Reports:/opt/robotframework/reports" \
            -v "${{ github.workspace }}/output:/opt/robotframework/output" \
            robotframework-tests:latest ${{ steps.config.outputs.execution_tool }} \
            ${{ steps.config.outputs.base_flags }} \
            ${{ steps.config.outputs.full_args }}

          ROBOT_EXIT_CODE=$?
          echo "✅ Full test suite completed with exit code: $ROBOT_EXIT_CODE"

      # Run single test suites (for non-"All" options)
      - name: Run Single Test Suite
        if: steps.config.outputs.run_type != 'smoke_first'
        run: |
          echo "🚀 Running ${{ github.event.inputs.test_suite }} with ${{ steps.config.outputs.execution_tool }} (${{ github.event.inputs.execution_mode }} mode)..."
          docker run --rm \
            -e ACCESS_TOKEN -e REFRESH_TOKEN -e CLIENT_ID -e CLIENT_SECRET -e WAF_BYPASS_SECRET -e TZ=Europe/Helsinki \
            -v "${{ github.workspace }}/TestSuites:/opt/robotframework/tests" \
            -v "${{ github.workspace }}/Reports:/opt/robotframework/reports" \
            -v "${{ github.workspace }}/output:/opt/robotframework/output" \
            robotframework-tests:latest ${{ steps.config.outputs.execution_tool }} \
            ${{ steps.config.outputs.base_flags }} \
            ${{ steps.config.outputs.suite_args }}

      # Parse Robot Framework XML results and create GitHub summary
      - name: Parse Test Results
        if: always() # Run even if tests failed
        run: |
          python3 << 'EOF'
          import xml.etree.ElementTree as ET
          import os
          import glob

          def parse_robot_results():
              # Find Robot Framework output.xml files, excluding pabot worker files
              all_output_files = glob.glob("Reports/**/output.xml", recursive=True)
              # Filter out pabot worker results - only use the main consolidated output.xml
              candidate_files = [f for f in all_output_files if 'pabot_results' not in f]
              
              print(f"Found {len(all_output_files)} total output.xml files")
              print(f"Found {len(candidate_files)} main output files (excluding pabot worker files)")
              for f in candidate_files:
                  print(f"  - {f}")
              
              # For "All" suite execution, prioritize full results over smoke results
              test_suite = "${{ github.event.inputs.test_suite }}"
              if test_suite == 'All' and len(candidate_files) > 1:
                  # Look for 'full' directory results first, then any non-smoke results
                  full_files = [f for f in candidate_files if '/full/' in f]
                  if full_files:
                      output_files = full_files
                      print(f"Using full test results: {output_files}")
                  else:
                      # If no 'full' directory, exclude smoke results to avoid duplication
                      output_files = [f for f in candidate_files if '/smoke/' not in f]
                      print(f"Using non-smoke results: {output_files}")
              else:
                  output_files = candidate_files
                  print(f"Using all available results: {output_files}")
              
              if not output_files:
                  print("::warning title=No Results::No Robot Framework output.xml files found")
                  # Create a basic summary even when no results are found
                  summary = "## 🤖 Test Results Summary\n\n"
                  summary += "⚠️ **No test results found** - The Robot Framework tests may not have executed properly.\n\n"
                  summary += "### Possible Issues:\n"
                  summary += "1. Docker container failed to start or execute tests\n"
                  summary += "2. Test files not found in the expected location\n"
                  summary += "3. Robot Framework execution failed before generating output files\n"
                  summary += "4. Volume mounting issues between host and container\n\n"
                  summary += "Check the step logs above for more detailed error information.\n"
                  
                  with open(os.environ['GITHUB_STEP_SUMMARY'], 'w') as f:
                      f.write(summary)
                  return
              
              total_passed = 0
              total_failed = 0
              failed_tests = []
              passed_tests = []
              
              # Check if we're in smoke-first mode and determine execution status
              test_suite = "${{ github.event.inputs.test_suite }}"
              smoke_execution_failed = os.environ.get('SMOKE_EXECUTION_FAILED', '') == 'true'
              
              # Determine if full suite actually ran by checking for multiple output files or full suite patterns
              full_suite_ran = False
              if test_suite == 'All':
                  # Check if we have results that indicate full suite execution
                  if len(output_files) > 1 or any('full' in f for f in output_files):
                      full_suite_ran = True
                  else:
                      # Check if we have a comprehensive set of results (not just smoke)
                      for output_file in output_files:
                          try:
                              tree = ET.parse(output_file)
                              root = tree.getroot()
                              test_count = len(root.findall('.//test'))
                              # If we have more than 20 tests, it's likely the full suite ran
                              if test_count > 20:
                                  full_suite_ran = True
                                  break
                          except:
                              pass
              
              # Parse each output.xml file
              for output_file in output_files:
                  try:
                      tree = ET.parse(output_file)
                      root = tree.getroot()
                      
                      # Extract individual test results
                      for test in root.findall('.//test'):
                          test_name = test.get('name', 'Unknown Test')
                          status = test.find('status')
                          
                          if status is not None:
                              if status.get('status') == 'PASS':
                                  total_passed += 1
                                  passed_tests.append(test_name)
                              else:
                                  total_failed += 1
                                  error_msg = status.text or 'No error message'
                                  failed_tests.append(f"{test_name}: {error_msg}")
                  
                  except Exception as e:
                      print(f"::warning title=Parse Error::Could not parse {output_file}: {e}")
              
              # Create GitHub Actions summary with test results
              summary = f"## 🤖 Test Results Summary\n\n"
              
              # Add execution mode information
              if test_suite == 'All':
                  if smoke_execution_failed:
                      summary += "🛑 **SMOKE TESTS FAILED** - Full test suite was blocked\n\n"
                      summary += "📋 **Next Steps**: Fix the failing smoke tests and re-run the workflow\n\n"
                  else:
                      summary += "✅ **FULL TEST SUITE EXECUTED** - All smoke tests passed, full suite completed\n\n"
                      if total_failed > 0:
                          summary += f"⚠️ Note: {total_failed} test cases failed in the full suite\n\n"
              
              summary += f"- ✅ **Passed**: {total_passed}\n"
              summary += f"- ❌ **Failed**: {total_failed}\n"
              summary += f"- 📊 **Total**: {total_passed + total_failed}\n\n"
              
              # Show failed tests (limit to 10 for readability)
              if failed_tests:
                  if test_suite == 'All' and smoke_execution_failed:
                      summary += "### 🚨 Smoke Test Execution Errors\n"
                  elif test_suite == 'All' and not full_suite_ran:
                      summary += "### 🚨 Failed Smoke Tests\n"
                  else:
                      summary += "### ❌ Failed Tests\n"
                  for i, test in enumerate(failed_tests[:10], 1):
                      summary += f"{i}. `{test}`\n"
                  if len(failed_tests) > 10:
                      summary += f"... and {len(failed_tests) - 10} more\n"
                  summary += "\n"
              
              # Show some passed tests (limit to 5)
              if passed_tests:
                  if test_suite == 'All' and not full_suite_ran:
                      summary += "### ✅ Passed Smoke Tests\n"
                  else:
                      summary += "### ✅ Passed Tests\n"
                  for i, test in enumerate(passed_tests[:5], 1):
                      summary += f"{i}. `{test}`\n"
                  if len(passed_tests) > 5:
                      summary += f"... and {len(passed_tests) - 5} more\n"
              
              # Write summary to GitHub Actions page
              with open(os.environ['GITHUB_STEP_SUMMARY'], 'w') as f:
                  f.write(summary)
              
              # Skip creating annotations here - let the final step handle all messaging
              # The summary will still show detailed results
              
              # Export the failure count for use in final step
              with open(os.environ['GITHUB_ENV'], 'a') as f:
                  f.write(f"TEST_FAILURE_COUNT={total_failed}\n")

          parse_robot_results()
          EOF
        env:
          SMOKE_EXECUTION_FAILED: ${{ env.SMOKE_EXECUTION_FAILED }}

      # Run HAR analyzer if HAR recording was enabled
      - name: Analyze HAR Files
        if: always() && github.event.inputs.enable_har_recording == 'true'
        run: |
          echo "📊 Analyzing HAR files..."
          
          # Check if HAR files exist
          if find output -name "*.har" -type f | grep -q .; then
            echo "HAR files found, running analysis..."
            docker run --rm \
              -v "${{ github.workspace }}:/opt/project" \
              -w /opt/project \
              robotframework-tests:latest \
              python3 har_analyzer.py | tee har_analysis_detailed.txt
            
            # Debug: Check what files were created
            echo "📁 Files in workspace root:"
            ls -la har_analysis_*.txt || echo "No har_analysis_*.txt files found in root"
            
            # Check if analysis output was created
            if [ -f har_analysis_summary.txt ]; then
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "## 📊 HAR Analysis Results" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo '```' >> $GITHUB_STEP_SUMMARY
              cat har_analysis_summary.txt >> $GITHUB_STEP_SUMMARY
              echo '```' >> $GITHUB_STEP_SUMMARY
            else
              echo "::warning title=HAR Analysis::HAR analysis completed but no summary file was generated"
            fi
          else
            echo "::warning title=No HAR Files::No HAR files found. HAR recording may not have been enabled properly."
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "## 📊 HAR Analysis Results" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "⚠️ **No HAR files found** - HAR recording may not have been enabled properly." >> $GITHUB_STEP_SUMMARY
          fi

      # Add execution metadata to GitHub summary
      - name: Generate Test Report Summary
        if: always() # Always show execution details
        run: |
          echo "## 📋 Test Execution Details" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Test Suite**: ${{ github.event.inputs.test_suite }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Execution Mode**: ${{ github.event.inputs.execution_mode }}" >> $GITHUB_STEP_SUMMARY
          echo "- **HAR Recording**: ${{ github.event.inputs.enable_har_recording }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Tool Used**: ${{ steps.config.outputs.execution_tool }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Execution Time**: $(date)" >> $GITHUB_STEP_SUMMARY
          echo "- **Runner**: ${{ runner.os }}" >> $GITHUB_STEP_SUMMARY

      # Upload all test reports as artifacts (always runs, even on failure)
      - name: Upload Test Reports
        if: always() # Ensure reports are saved even if tests fail
        uses: actions/upload-artifact@v4
        with:
          name: test-reports-${{ github.run_number }} # Unique name per run
          path: Reports/
          retention-days: 30 # Keep reports for 30 days

      # Upload HAR files and analysis results if HAR recording was enabled
      - name: Upload HAR Analysis Results
        if: always() && github.event.inputs.enable_har_recording == 'true'
        run: |
          echo "📦 Preparing HAR analysis artifacts..."
          echo "Files in workspace:"
          ls -la har_analysis_*.txt || echo "No har_analysis files found"
          echo "Files in output:"
          find output -name "*.har" -type f | head -5 || echo "No HAR files found"
        
      - name: Upload HAR Analysis Artifacts  
        if: always() && github.event.inputs.enable_har_recording == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: har-analysis-${{ github.run_number }}
          path: |
            output/**/*.har
            har_analysis_summary.txt
            har_analysis_detailed.txt
          retention-days: 30
          if-no-files-found: warn

      - name: Upload HAR Analysis Text Files Only
        if: always() && github.event.inputs.enable_har_recording == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: har-analysis-text-${{ github.run_number }}
          path: |
            har_analysis_summary.txt
            har_analysis_detailed.txt
          retention-days: 30
          if-no-files-found: warn


            # Fail the workflow if smoke tests failed or if any tests failed
      - name: Fail Workflow on Test Failures
        if: always()
        run: |
          # 1) If smoke blocked full suite, report and exit
          if [ "$SMOKE_EXECUTION_FAILED" = "true" ]; then
            echo "::error title=Smoke Tests Failed::Smoke tests failed—full suite was blocked"
            exit 1
          fi

          # 2) If any tests failed, report with count and exit
          if [ "${TEST_FAILURE_COUNT:-0}" -gt 0 ]; then
            echo "::error title=Test Failures::${TEST_FAILURE_COUNT} test(s) failed"
            exit 1
          fi

          # 3) All tests passed
          echo "::notice title=All Tests Passed::All tests passed!"
